{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from config import CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text: str) -> str:\n",
    "    tokens = word_tokenize(text)\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    stop_words = set(stopwords.words('russian'))\n",
    "    tokens = [word for word in tokens if not word in stop_words]\n",
    "#     stemmer = SnowballStemmer(\"russian\") \n",
    "#     tokens = [stemmer.stem(word) for word in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news = pd.read_csv(f'{CONFIG.DATA_FOLDER}/russian_news.csv')\n",
    "df_cvs = pd.read_csv(f'{CONFIG.DATA_FOLDER}/rabota_cvs.csv')\n",
    "df_vacs = pd.read_csv(f'{CONFIG.DATA_FOLDER}/hh_vacancies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение резюме и новостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = min(len(df_cvs), len(df_news))\n",
    "cvs = df_cvs['text'][:N]\n",
    "news = df_news['text'][:N]\n",
    "\n",
    "cvs = [text_preprocessing(item) for item in cvs]\n",
    "news = [text_preprocessing(item) for item in news]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = cvs + news\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "X = vectorizer.fit_transform(corpus).toarray()\n",
    "y =  [1] * N + [0] * N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pprint_metrics_for_models(X, y, classifiers, metrics, print_train=False, print_test=True):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0, stratify=y)\n",
    "    for classifier in classifiers:\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_train_pred = classifier.predict(X_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        print(f'{classifier.__class__.__name__} results')\n",
    "        if print_train:\n",
    "            print('Train results')\n",
    "            for metric in metrics:\n",
    "                print(f'{metric.__name__} : {round(metric(y_train, y_train_pred), 3)}')\n",
    "        if print_test:\n",
    "            print('Test results')\n",
    "            for metric in metrics:\n",
    "                print(f'{metric.__name__} : {round(metric(y_test, y_pred), 3)}')\n",
    "        print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB results\n",
      "Test results\n",
      "accuracy_score : 0.997\n",
      "precision_score : 1.0\n",
      "recall_score : 0.994\n",
      "f1_score : 0.997\n",
      "\n",
      "MultinomialNB results\n",
      "Test results\n",
      "accuracy_score : 1.0\n",
      "precision_score : 1.0\n",
      "recall_score : 1.0\n",
      "f1_score : 1.0\n",
      "\n",
      "BernoulliNB results\n",
      "Test results\n",
      "accuracy_score : 0.999\n",
      "precision_score : 0.998\n",
      "recall_score : 1.0\n",
      "f1_score : 0.999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [GaussianNB(), MultinomialNB(), BernoulliNB()]\n",
    "metrics = [accuracy_score, precision_score, recall_score, f1_score]\n",
    "pprint_metrics_for_models(X, y, classifiers, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение вакансий и новостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = min(len(df_news), len(df_vacs))\n",
    "vacs = df_vacs['text'][:N]\n",
    "news = df_news['text'][:N]\n",
    "\n",
    "vacs = [text_preprocessing(item) for item in vacs]\n",
    "news = [text_preprocessing(item) for item in news]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = vacs + news\n",
    "# vectorizer = CountVectorizer(max_features=5000)\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "X = vectorizer.fit_transform(corpus).toarray()\n",
    "y =  [1] * N + [0] * N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB results\n",
      "Test results\n",
      "accuracy_score : 0.995\n",
      "precision_score : 0.99\n",
      "recall_score : 1.0\n",
      "f1_score : 0.995\n",
      "\n",
      "MultinomialNB results\n",
      "Test results\n",
      "accuracy_score : 0.999\n",
      "precision_score : 0.998\n",
      "recall_score : 1.0\n",
      "f1_score : 0.999\n",
      "\n",
      "BernoulliNB results\n",
      "Test results\n",
      "accuracy_score : 0.989\n",
      "precision_score : 1.0\n",
      "recall_score : 0.978\n",
      "f1_score : 0.989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [GaussianNB(), MultinomialNB(), BernoulliNB()]\n",
    "metrics = [accuracy_score, precision_score, recall_score, f1_score]\n",
    "pprint_metrics_for_models(X, y, classifiers, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение резюме и вакансий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = min(len(df_cvs), len(df_vacs))\n",
    "cvs = df_cvs['text'][:N]\n",
    "vacs = df_vacs['text'][:N]\n",
    "\n",
    "cvs = [text_preprocessing(item) for item in cvs]\n",
    "vacs = [text_preprocessing(item) for item in vacs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = cvs + vacs\n",
    "# vectorizer = CountVectorizer(max_features=5000)\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "X = vectorizer.fit_transform(corpus).toarray()\n",
    "y =  [1] * N + [0] * N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB results\n",
      "Test results\n",
      "accuracy_score : 0.979\n",
      "precision_score : 1.0\n",
      "recall_score : 0.958\n",
      "f1_score : 0.979\n",
      "\n",
      "MultinomialNB results\n",
      "Test results\n",
      "accuracy_score : 0.997\n",
      "precision_score : 0.998\n",
      "recall_score : 0.996\n",
      "f1_score : 0.997\n",
      "\n",
      "BernoulliNB results\n",
      "Test results\n",
      "accuracy_score : 0.983\n",
      "precision_score : 0.969\n",
      "recall_score : 0.998\n",
      "f1_score : 0.983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [GaussianNB(), MultinomialNB(), BernoulliNB()]\n",
    "metrics = [accuracy_score, precision_score, recall_score, f1_score]\n",
    "pprint_metrics_for_models(X, y, classifiers, metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
